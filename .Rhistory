example(lm)
?gl
group <- gl(2, 10, 20, labels = c("Ctl","Trt"))
group
class(group)
weight <- c(ctl, trt)
weight
group
weight
example(lm)
plot(cars, col='blue', pch=20, cex=2, main="Relationship between
Speed and Stopping Distance for 50 Cars", xlab="Speed in mph",
ylab="Stopping Distance in feet")
set.seed(122)
speed.c = scale(cars$speed, center=TRUE, scale=FALSE)
mod1 = lm(formula = dist ~ speed.c, data = cars)
summary(mod1)
mod2 = lm(formula = dist ~ speed, data = cars)
summary(mod2)
speed.var <-var(cars$speed)
speed.var
attach(cars)
dist.var <-var(dist)
dist.var
mod2.fitted.value
mod2.fitted.values
fv <-mod2$fitted.values
fv
summary(fv)
sum(dist)
summary(dist)
fv-mean(dist)
(fv-mean(dist))^2
sum((fv-mean(dist))^2)
mod2$residuals
mod2$residuals^2
sum(mod2$residuals^2)
sum((dist - mean(dist))^2)
var(dist)
?var
11353/32538
sd(dist)
c(1:5)^2
dist.var * length(dist)
dist.var <-var(dist) * length(dist)
dist.var
fv <-mod2$fitted.values - mean(dist)
ss.reg <- sum(fv^2)
ss
ss.reg
ss.res <- sum(mod2$residuals^2)
ss.res
ss.res + ss.reg
dist.var
sum((dist-mean(dist))^2)
var(dist) * length(dist)
(ss.res + ss.reg)/length(dist)
var(dist)
(ss.res + ss.reg)/(length(dist)-1)
dist.var <-var(dist) * (length(dist)-1)
dist.var
ss.total <-var(dist) * (length(dist)-1)
ss.total
c(ss.reg, ss.res)/ss.toal
c(ss.reg, ss.res)/ss.total
summary(mod2)
str(mod2)
names(mod2)
mod2$df.residual
summary(mod2)
sd(mod2$residuals)
res <- mod2$residuals
sum((res - mean(res)^2)
)
sum((res - mean(res))^2)
sum((res - mean(res))^2)/length(dist)
sqrt(sum((res - mean(res))^2)/length(dist))
sqrt(sum((res - mean(res))^2)/(length(dist)-1)
sqrt(sum((res - mean(res))^2)/(length(dist)-1)
sum((res - mean(res))^2)/->sr
sum((res - mean(res))^2)->sr
length(dist)
sqrt(sr/49)
sd(mod2$residuals)
plot(mod2$residuals)
c(ss.reg, ss.res)/ss.total
str(mod2)
c(ss.reg, ss.res)/ss.total ->r.square
r.square * length(dist)/(1-r.square)
r.square * length(dist)/(1-r.square)
r.square * length(dist)/(1-r.square[1])
r.square[1] * length(dist)/(1-r.square[1])
r.square[1] * (length(dist)-1)/(1-r.square[1])
r.square
r.square[1] * (length(dist)-2)/(1-r.square[1])
summary(mod2)
qf(0.95, df1=1, df2=48)
summary(mod2$residuals)
var(mod2$residuals)
sd(mod2$residuals)
sqrt(var(mod2$residuals)/48)
sum(mod2$residuals^2)
mod2$residuals
sum(mod2$residuals^2)
var(mod2$residuals)
var(mod2$residuals^2)
sqrt(var(mod2$residuals^2)/48)
sqrt(sum(mod2$residuals^2)/48)
4+4
alligator <- data.frame(
lnLength = c(3.87, 3.61, 4.33, 3.43, 3.81, 3.83, 3.46, 3.76,
3.50, 3.58, 4.19, 3.78, 3.71, 3.73, 3.78),
lnWeight = c(4.87, 3.93, 6.46, 3.33, 4.38, 4.70, 3.50, 4.50,
3.58, 3.64, 5.90, 4.43, 4.38, 4.42, 4.25)
)  -> data
# visualize
plot(alligator)
# linear mode: dn for short name
alli.mod1 = lm(lnWeight ~ lnLength, data = alligator) -> dn
# section: residuals = difference of  the observed  and predict values
dn$residuals
# section: coefficients
#
# section: analysis of variance (multiple R^2 and adjusted R^2)
tss <- var(data$lnWeight) * (nrow(data)-1 )
sse <- sum(dn$residuals^2)
regSS  <- tss - sse
# Residual standard error: 0.1229 on 13 degrees of freedom
res.sd = sqrt(sse / (nrow(data)-2))
# multiple R^2
r.squared = regSS / tss # proportion of the var in Y that is explained by
# linear regression
# the adjusted R^2: follows
# 1 - (1- R^2)(n-1)/(n-1-k), where k = number of predictors
# 1 -R^2 = sse/tss
r.sq.adj = 1 - sse *(nrow(data[1])-1)/tss/(nrow(data[1])-2)
#section: F-statistic: and   p-value:
#  F = (r^2/k)/ ( (1-R^2)/(n-1-k)) test the significance of R^2
# p-value is the prob for F with df1=k, df2 = n-1-k
#
F.stat = r.squared/((1-r.squared)/(nrow(data)-2))
F.pvalue = pf(F.stat, df1 =1, df2 = (nrow(data)-2), lower.tail = F)
summary(dn)
res.sd
len <- c(data[,1])
var(len)
(len-mean(len))^2
sum( (len-mean(len))^2)
sum( (len-mean(len))^2) /nrow(data) ->x.var
x.var
var(len)/nrow(data)
print(var())
print(var
)
ds <-1:5
var(ds)
ds - mean(ds)
(ds - mean(ds))^2
sum((ds - mean(ds))^2)
var(ds)
sqrt(sse/14)/sd(len)
sqrt(sse/13)/sd(len)
sqrt(sse/13)/sqrt(var(len)*13/14)
sqrt(sse/14)/sqrt(var(len)*13/14)
summary(dn)
coef(summary(dn))[, "Std. Error"]
coef(summary(dn))
dn$coefficients
str(coef(summary(dn))
)
coef(summary(dn))[1,]
coef(summary(dn))[,1]
dn$sigma
dn[[6]]
sqrt(sse/15)
sqrt(sse/13)
sqrt(sse/13)/sqrt(var(len)*14)
sqrt(sse/13)/sd(len)
sqrt(sse/13)/sd(len) *sqrt(15/14)
x.var
sqrt(sse/13)/sqrt(x.var)
dn$residuals
resid(dn)
var(dn$residuals)
var(dn$residuals) *13
sd(dn$residuals)
res.sd = sqrt(sse / (nrow(data)-2))
res.sd
res.sd/sd(len)
res.sd/sd(len) * sqrt(15/14)
coef(summary(dn)) # coefficents
15 *sum(len^2) - sum(len)^2
15 *sum(len^2) - sum(len)^2 ->ss
res.sd/sqrt(ss/15)
len
data[,1]
sd(len)
res.sd/sd(len)
res.sd = sqrt(sse / (nrow(data)-2))
res.sd
var(len)
sqrt(var(len))
(15 * sum(len^2) - sum(len)^2)/(14*15) ->ss
res.sd/sqrt(ss)
(15 * sum(len^2) - (sum(len))^2)/(14*15) ->ss
res.sd/sqrt(ss)
(15 * sum(len^2) - (sum(len))^2)/(15*15) ->ss
res.sd/sqrt(ss)
summary(dn)
res.sd/sd(len)
name(data)
names(data)
var(len)
res.sd/sqrt(var(len)*14)
res.sd/sd(c(data[,1]))
res.sd/sqrt(var(c(data[,1]))*14)
res.sd/sqrt(var(c(data[,1]))*(nrow(data)-1)
)
res.sd/sqrt(var(c(data[,1]))*(nrow(data)-1))
dn$coefficients
dn$coefficients[2]
res.sd/sqrt(var(c(data[,1]))*(nrow(data)-1)) ->StdErr.b
dn$coefficients[2]/StdErr.b
dn$coefficients[2]/StdErr.b -> t.val.b
dn$coefficients[2]/StdErr.b -> t.value1
c(StdErr.b, t.value1)
summary(dn)
?pt
pt(t.value1, df=13, lower.tail = F)
pt(t.value1, df=13, lower.tail = T)
pt(t.value1, df=13, lower.tail = F)
pt(t.value1, df=13, lower.tail = F) *2
pt(t.value1, df=13, lower.tail = F) *2
alligator <- data.frame(
lnLength = c(3.87, 3.61, 4.33, 3.43, 3.81, 3.83, 3.46, 3.76,
3.50, 3.58, 4.19, 3.78, 3.71, 3.73, 3.78),
lnWeight = c(4.87, 3.93, 6.46, 3.33, 4.38, 4.70, 3.50, 4.50,
3.58, 3.64, 5.90, 4.43, 4.38, 4.42, 4.25)
)  -> data
# visualize
plot(alligator)
# linear mode: dn for short name
alli.mod1 = lm(lnWeight ~ lnLength, data = alligator) -> dn
# section: residuals = difference of  the observed  and predict values
summary(dn)
d1 <- c(data[,1])
d1 <- c(data[,1]); d2 <- c(data[,2])
d1,d2
d1; d2
cov(d1,d2)/cov(d1,d1)/cov(d2,d2)
sum((d1-mean(d1))*(d1-mean(d2)))
sum((d1-mean(d1))*(d2-mean(d2)))
sum((d1-mean(d1))*(d2-mean(d2)))/sqrt(var(d1)*14 * var(d2)*14)
tss <- var(data$lnWeight) * (nrow(data)-1 )
sse <- sum(dn$residuals^2)
regSS  <- tss - sse
# Residual standard error: 0.1229 on 13 degrees of freedom
res.sd = sqrt(sse / (nrow(data)-2))
res.sd
# multiple R^2
r.squared = regSS / tss # proportion of the var in Y that is explained by
# linear regression
# the adjusted R^2: follows
# 1 - (1- R^2)(n-1)/(n-1-k), where k = number of predictors
# 1 -R^2 = sse/tss
r.squared                        # linear regression
sum((d1-mean(d1))*(d2-mean(d2)))/sqrt(var(d1)*14 * var(d2)*14)
r.squared^2
sqrt(r.squared)
sum((d1-mean(d1))*(d2-mean(d2)))/sqrt(var(d1)*14 * var(d2)*14) ->r.val
cov(d1,d2)/cov(d1,d1)/cov(d2,d2)
cov(d1,d2)/sqrt)cov(d1,d1)*cov(d2,d2))
cov(d1,d2)/sqrt(cov(d1,d1)*cov(d2,d2))
c(r.val^2, r.squared)
pima <- read.table("http://archive.ics. uci.edu/ml/machine -learning -databases /pima-indians-diabetes/pima-indians- diabetes.data", header=F, sep=",")
pima <- read.table("http://archive.ics.uci.edu/ml/machine -learning -databases /pima-indians-diabetes/pima-indians- diabetes.data", header=F, sep=",")
pima <- read.table("http://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data", header=F, sep=",")
summary(pima)
url < paste("http://archive.ics.uci.edu/ml/",
url
?paste
Url < paste(c("http://archive.ics.uci.edu/ml/",
"machine-learning-databases/",
"pima-indians-diabetes/pima-indians-diabetes.data"), sep ="")
Url <- paste(c("http://archive.ics.uci.edu/ml/",
"machine-learning-databases/",
"pima-indians-diabetes/pima-indians-diabetes.data"), sep ="")
pima <- read.table("http://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data", header=F, sep=",")
Url <- paste(c("http://archive.ics.uci.edu/ml/",
"machine-learning-databases/",
"pima-indians-diabetes/pima-indians-diabetes.data"), sep ="")
Url <- paste(c("http://archive.ics.uci.edu/ml/",
Url <- paste(c("http://archive.ics.uci.edu/ml/",
"machine-learning-databases/",
"pima-indians-diabetes/pima-indians-diabetes.data"), sep ="")
pima <- read.table(Url, header=F, sep=",")
pima <- read.table(Url, header=F, sep=",")
Url
Url <- paste("http://archive.ics.uci.edu/ml/",
"machine-learning-databases/",
"pima-indians-diabetes/pima-indians-diabetes.data", sep ="")
pima <- read.table(Url, header=F, sep=",")
summary(pima)
help(pima)
row.names(pima)
dim(pima)
colnames(pima)
colnames(pima) <- c("npreg", "glucose", "bp", "triceps", "insulin", "bmi",
"diabetes", "age", "class")
head(pima)
pima$glucose[pima$glucose==0] <- NA
pima$bp[pima$bp==0] <- NA
pima$triceps[pima$triceps==0] <- NA
pima$insulin[pima$insulin==0] <- NA
pima$bmi[pima$bmi==0] <- NA
pima$class <- factor (pima$class)
pima$class
levels(pima$class) <- c("neg", "pos")
pima$class
summary(pima)
head(prestige)
head(Prestige)
library(cars)
library(car)
data("cars")
head(Prestige)
datasets()
data()
install.packages("car")
library(car)
library(corrplot) # We'll use corrplot later on in this example too.
library(visreg) # This library will allow us to show multivariate graphs.
library(rgl)
library(knitr)
library(scatterplot3d)
library(corrplot); # We'll use corrplot later on in this example too.
library(visreg); # This library will allow us to show multivariate graphs.
library(rgl);
library(knitr);
library(scatterplot3d)
install.packages(corrplot); # We'll use corrplot later on in this example too.
install.packages("corrplot""); # We'll use corrplot later on in this example too.
install.packages("corrplot");
install.packages("rgl");
head(Prestige,5)
dim(Prestige)
str(Prestige)
help("Prestige")
newdata = Prestige[,c(1:4)]
summary(newdata)
plot(newdata, pch=16, col="blue", main="Matrix Scatterplot of Income,
Education, Women and Prestige")
plot(newdata, pch=19, col="blue", main="Matrix Scatterplot of Income,
Education, Women and Prestige")
set.seed(1)
education.c = scale(newdata$education, center=TRUE, scale=FALSE)
prestige.c = scale(newdata$prestige, center=TRUE, scale=FALSE)
women.c = scale(newdata$women, center=TRUE, scale=FALSE)
new.c.vars = cbind(education.c, prestige.c, women.c)
newdata = cbind(newdata, new.c.vars)
names(newdata)[5:7] = c("education.c", "prestige.c", "women.c" )
summary(newdata)
mod1 = lm(income ~ education.c + prestige.c + women.c, data=newdata)
summary(mod1)
mod2 = lm(income ~ prestige.c + women.c, data=newdata)
summary(mod2)
# Plot model residuals.
plot(mod2, pch=16, which=1)
plot(mod2, pch=16, which=2)
plot(mod2, pch=16, which=3)
plot(mod2, pch=16, which=1)
hsb2 <- read.csv("http://www.ats.ucla.edu/stat/data/hsb2.csv")
hsb2$race.f <- factor(hsb2$race)
is.factor(hsb2$race.f)
hsb2
head(hsb2)
fit <- lm(write ~ race.f, data = hsb2)
summary(fit)
factor(hsb2$race.f)
summary(hsb2$race.f)
setwd("~/prog/R/R-learning")
s <-c(15,10,12,8,21,7,13,3,
20, 13, 9, 22, 24, 25,18,12,
10,24,29,12,27,21,25,14,
30,22, 26,20,29, 28, 25,15)
length(s)
f<-rep(1:4, each=8)
f
df <- data.frame(s, f)
df
aggregate(s, by=f, mean)
aggregate(s, by=list(f), mean)
aggregate(s, by=list(f), var)
result <- anova(s, f, data=df)
?anova
result <- anova(s~f, data=df)
library(stats)
result <- anova(s~f, data=df)
plot(s~f, data=df)
plot(s~factor(f), data=df)
result <- aov(s~f, data=df)
summary(result)
?aov
result <- aov(s~factor(f), data=df)
summary(result)
result$coefficients
result$residuals
str(result)
mean(s)
result$coefficients
mod2 <-lm(s~factor(f), data=df)
summary(mod2)
summary(result)
ss.total = var(s) * (length(s)-1)
ss.total
mean.lst <- rep(aggregate(s, by=factor(f), mean), each = 8)
mean.lst <- rep(aggregate(s, by=list(f), mean), each = 8)
mean.lst
mean.lst <- rep(aggregate(s, by=list(f), mean), each = 8)
mean.lst
mean.lst <- rep(c(aggregate(s, by=list(f), mean)), each = 8)
mean.lst
mean.lst
mean.lst <- rep(c(aggregate(s, by=list(f), mean)), times = 8)
mean.lst
?rep
c(aggregate(s,by=list(f), mean()))
c(aggregate(s,by=list(f), mean
)
)
c(aggregate(s,by=list(f), mean))
c(aggregate(s,by=list(f), mean))[x]
s
f
mean.lst <- rep(c(aggregate(s, by=list(f), mean)), times = 8)
mean.lst
str(mean.lst)
mean.lst <- rep(c(aggregate(s, by=list(f), mean)), times = c(8,8,8,8))
mean.lst <- rep(c(aggregate(s, by=list(f), mean)), each = c(8,8,8,8))
aggregate(s, by=list(f), mean) -> ave
ave
ave[1]
ave[2]
mean.lst <- rep(c(aggregate(s, by=list(f), mean))[2], each = 8
mean.lst <- rep(c(aggregate(s, by=list(f), mean))[2], each = 8)
mean.lst <- rep(aggregate(s, by=list(f), mean)[2], each = 8)
mean.lst
mean.lst <- rep(ave, each = 8)
mean.lst
mean.lst <- rep(ave[2], each = 8)
mean.lst
mean.lst <- rep(ave[2], times = 8)
mean.lst
ave[2]
str(ave[2])
mean.lst <- rep(c(ave[2]), times = 8)
mean.lst
ave[2]
ave[2][x]
ave[2]['x'']
ave[2]['x']
ave[,2]
mean.lst <- rep(c(ave[,2]), times = 8)
mean.lst
mean.lst <- rep(c(ave[,2]), each = 8)
mean.lst
mean.ftr <- rep(c(ave[,2]), each = 8)
mean.ftr
mean.factor <- rep(c(ave[,2]), each = 8)
mean.factor
sum((s- mean.factor)^2)
ss.within <-sum((s- mean.factor)^2)
ss.betw <- sum((mean.factor- mean(s))^2)
ss.betw, ss.within
(ss.betw, ss.within)
c(ss.betw, ss.within)
c(ss.betw, ss.within, ss.total)
MS.betw <-ss.betw/3
MS.within <- ss.within/28
c(MS.betw, MS.within)
f.value <- MS.betw/MS.within
c(MS.betw, MS.within, f.value)
?pf
pf(f.value, 3, 28)
1- pf(f.value, 3, 28)
pr <- 1 -pf(f.value, 3, 28)
c(MS.betw, MS.within, f.value)
str(result)
result$fitted.values
str(result$fitted.values)
mean.factor <- result$fitted.values
mean.factor
ss.within <-sum((s- mean.factor)^2)
ss.betw <- sum((mean.factor- mean(s))^2)
c(ss.betw, ss.within, ss.total)
MS.betw <-ss.betw/3
MS.within <- ss.within/28
f.value <- MS.betw/MS.within
pr <- 1 -pf(f.value, 3, 28)
c(MS.betw, MS.within, f.value)
str(result)
names(result)
result$effects
result$rank
result$assign
result$qr
result$df.residual
result$model
result$terms
plot(result$residuals~factor(f))
plot(result$residuals~(f))
aggregate(s, by=list(f), var)
